{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../datasets/emscad_v1.csv\")\n",
    "#print(dataset.head())\n",
    "#print(dataset.shape)\n",
    "\n",
    "def duplicatedChecking(df):\n",
    "    print(\"Number of duplicated rows detected\",df.duplicated().sum()) # Check for Duplicated rows\n",
    "    df.drop_duplicates(inplace=True) #Remove dupes\n",
    "    print(\"Duplicated rows removed, updated rows\",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[['country', 'state', 'city']] = dataset['location'].str.split(', ', expand=True, n = 2) #Seperating location column into respective categories \n",
    "location_to_fill_na = ['country', 'state', 'city'] \n",
    "dataset[location_to_fill_na] = dataset[location_to_fill_na].replace('', np.nan) #Fill empty fields with NaN\n",
    "\n",
    "dataset[['min_salary', 'max_salary']] = dataset['salary_range'].str.split('-', expand=True, n = 1) #Seperating salary column into respective categories \n",
    "salary_to_fill_na = ['min_salary', 'max_salary']\n",
    "dataset[salary_to_fill_na] = dataset[salary_to_fill_na].replace('', np.nan) #Fill empty fields with NaN   \n",
    "\n",
    "dataset = dataset.drop(['location', 'salary_range'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicatedChecking(dataset) \n",
    "print(dataset.info()) # Check col datatypes\n",
    "print(dataset.describe()) \n",
    "\n",
    "print(dataset.columns[3]) # salary range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pie Chart displaying the number of fraudulent and legitimate jobs\n",
    "dataset['fraudulent'] = dataset['fraudulent'].apply(lambda x: 1 if x == \"t\" else 0)\n",
    "fraud_count = (dataset['fraudulent'] == 1).sum()\n",
    "nonfraud_count = (dataset['fraudulent'] == 0).sum()\n",
    "fraudpie = np.array([fraud_count, nonfraud_count])\n",
    "labels = [\"Fraudulent\", \"Non-Fraudulent\"]\n",
    "plt.pie(fraudpie, labels = labels, autopct=lambda p: '{:.0f}'.format(p * sum(fraudpie) / 100))\n",
    "plt.title('No. of Legitimate Job Postings')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the times a country appears in the dataset\n",
    "item_counts = Counter(dataset['country'])\n",
    "\n",
    "print (item_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization of Country Posting Data\n",
    "countries = ['US', 'GB', 'GR', 'CA', 'DE', 'NZ', 'IN', 'AU', 'PH', 'NL']\n",
    "values = [10495, 2336, 939, 450, 382, 330, 274, 213, 132, 126]\n",
    "\n",
    "# Create a horizontal bar graph\n",
    "plt.barh(countries, values, color='skyblue')\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('No. of Postings')\n",
    "plt.ylabel('Countries')\n",
    "plt.title('Top 10 Countries with Job Postings')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
