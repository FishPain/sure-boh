{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/ifish/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import joblib\n",
    "import shutil\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import Normalizer, MultiLabelBinarizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.combine import SMOTETomek\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from gensim.parsing.porter import PorterStemmer\n",
    "\n",
    "# modelling\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y, label):\n",
    "    \"\"\"\n",
    "    :param model: model to evaluate\n",
    "    :param X: features\n",
    "    :param y: target\n",
    "    :param label: label for the model \n",
    "\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X)\n",
    "\n",
    "    print(label + ' Set')\n",
    "    print(\"Accuracy:\", accuracy_score(y, y_pred))\n",
    "    print(\"F1 Score:\", f1_score(y, y_pred, average='macro'))\n",
    "    print()\n",
    "\n",
    "    print(\"Classification Report\")\n",
    "\n",
    "\n",
    "    print(classification_report(y, y_pred, digits=4))\n",
    "    \n",
    "\n",
    "\n",
    "def get_score(model, X, y):\n",
    "    \"\"\"\n",
    "    :param model: model to evaluate\n",
    "    :param X: features\n",
    "    :param y: target\n",
    "\n",
    "    \"\"\"\n",
    "    cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=42)\n",
    "    print('Accuracy: ', cross_val_score(model, X, y, cv=cv, scoring='accuracy').mean())\n",
    "    print('Precision Macro: ', cross_val_score(model, X, y, cv=cv, scoring='precision_macro').mean())\n",
    "    print('Recall Macro: ', cross_val_score(model, X, y, cv=cv, scoring='recall_macro').mean())\n",
    "    print('F1 Macro: ', cross_val_score(model, X, y, cv=cv, scoring='f1_macro').mean())\n",
    "    \n",
    "def compress_file(input_file, output_tar_gz):\n",
    "    shutil.make_archive(output_tar_gz, 'xztar', '.', input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../datasets/emscad_v1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['title', 'location', 'department', 'salary_range', 'company_profile',\n",
       "       'description', 'requirements', 'benefits', 'telecommuting',\n",
       "       'has_company_logo', 'has_questions', 'employment_type',\n",
       "       'required_experience', 'required_education', 'industry', 'function',\n",
       "       'fraudulent', 'in_balanced_dataset'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['description', 'requirements', 'benefits', 'fraudulent']].fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"feature\"] = df['description'] + \" \"+ df['requirements'] + \" \" + df['benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'<[^>]*>', '')\n",
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'&[^;]*;', '')\n",
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:5: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'\\\\[a-z]*', '')\n",
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:7: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'[^\\w\\s]', '')\n",
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:9: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'\\d+', '')\n",
      "/var/folders/w8/m8cskjbx3p11jckbyyl93p7w0000gn/T/ipykernel_3082/1334024712.py:11: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['feature'] = df['feature'].str.replace(r'\\s+', ' ')\n"
     ]
    }
   ],
   "source": [
    "df['feature'] = df['feature'].str.lower()\n",
    "# remove html tags and word that start with & and \\\n",
    "df['feature'] = df['feature'].str.replace(r'<[^>]*>', '')\n",
    "df['feature'] = df['feature'].str.replace(r'&[^;]*;', '')\n",
    "df['feature'] = df['feature'].str.replace(r'\\\\[a-z]*', '')\n",
    "# remove punctuation\n",
    "df['feature'] = df['feature'].str.replace(r'[^\\w\\s]', '')\n",
    "# remove digits\n",
    "df['feature'] = df['feature'].str.replace(r'\\d+', '')\n",
    "# remove whitespace\n",
    "df['feature'] = df['feature'].str.replace(r'\\s+', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenise\n",
    "df['feature'] = df['feature'].apply(lambda x: word_tokenize(x.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['feature', 'fraudulent']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove stopwords\n",
    "all_stopwords = set(stopwords.words('english'))\n",
    "all_stopwords.update(['\\\\r\\\\n'])\n",
    "df['feature'] = df['feature'].apply(lambda x: [word for word in x if word not in all_stopwords])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stem words\n",
    "df['feature'] = df['feature'].apply(lambda x: [PorterStemmer().stem(word) for word in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature'] = df['feature'].apply(lambda x: [word for word in x if len(word) >= 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['feature'] = df['feature'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows wwith empty str\n",
    "df = df[df['feature'] != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['fraudulent'] = df['fraudulent'].apply(lambda x: 1 if x == \"t\" else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature extraction using tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the text data using TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "dtm = tfidf.fit_transform(df['feature'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionsality reduction using SVD <br>\n",
    "This removes the less important variables in my dataset and improves training speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimension = 500\n",
    "svd = TruncatedSVD(dimension, random_state=42)\n",
    "dtm_svd = svd.fit_transform(dtm)\n",
    "# Apply Normalizer to normalize the data\n",
    "dtm_svd_normalized = Normalizer(copy=False)\n",
    "dtm_svd_normalized = dtm_svd_normalized.fit_transform(dtm_svd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(dtm_svd)\n",
    "x.reset_index(inplace=True, drop=True)\n",
    "y = df['fraudulent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf, x_train, y_train, 'Train')\n",
    "evaluate_model(rf, x_test, y_test, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use SMOTETomek to oversample the minority class\n",
    "x_res, y_res = SMOTETomek(sampling_strategy='all', random_state=42).fit_resample(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_res, y_res, test_size=0.2, random_state=42, stratify=y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_model(rf, x_train, y_train, 'Train')\n",
    "evaluate_model(rf, x_test, y_test, 'Test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a pipeline for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make pipeline\n",
    "tfidf = TfidfVectorizer()\n",
    "svd = TruncatedSVD(n_components=350, random_state=42)\n",
    "norm = Normalizer(copy=False)\n",
    "smote = SMOTETomek(sampling_strategy='all', random_state=42)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "pipe = make_pipeline(tfidf, svd, norm, smote, rf)\n",
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    df['feature'], df['fraudulent'], test_size=0.2, random_state=42, stratify=df['fraudulent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('truncatedsvd',\n",
       "                 TruncatedSVD(n_components=350, random_state=42)),\n",
       "                ('normalizer', Normalizer(copy=False)),\n",
       "                ('smotetomek',\n",
       "                 SMOTETomek(random_state=42, sampling_strategy='all')),\n",
       "                ('randomforestclassifier',\n",
       "                 RandomForestClassifier(random_state=42))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Set\n",
      "Accuracy: 0.9999300845976369\n",
      "F1 Score: 0.9996201002783337\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    1.0000    1.0000     13611\n",
      "           1     1.0000    0.9986    0.9993       692\n",
      "\n",
      "    accuracy                         0.9999     14303\n",
      "   macro avg     1.0000    0.9993    0.9996     14303\n",
      "weighted avg     0.9999    0.9999    0.9999     14303\n",
      "\n",
      "Test Set\n",
      "Accuracy: 0.982662192393736\n",
      "F1 Score: 0.887844794094794\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9827    0.9994    0.9910      3403\n",
      "           1     0.9826    0.6532    0.7847       173\n",
      "\n",
      "    accuracy                         0.9827      3576\n",
      "   macro avg     0.9826    0.8263    0.8878      3576\n",
      "weighted avg     0.9827    0.9827    0.9810      3576\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluate_model(pipe, x_train, y_train, 'Train')\n",
    "evaluate_model(pipe, x_test, y_test, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/rf.pkl']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joblib.dump(pipe, '../models/rf.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f48b1a2c38788c4a91ce3e7692fc5e2582621afc45073ba526ca796c7ef760f3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
